#!/usr/bin/env python3
"""
Write info about the system to a FOLDER/system_details.pickle.

Usage:
    info.py DIR [options]

Options:
    -h, --help               Show this help.
    -c, --concurrent=N       Specify number of simultaenous runs jobs.
    -e, --exec=FILE          Specify executable path.
    -r, --runs=N             Specify number of runs.
    -t, --total=N            Specify total number of jobs.


Description:
    concurrent      - number of jobs running simultaneously.
    runs            - the number of times to run a single input.
    total_num_jobs  - number of jobs generated by src/jobs.py
    total_num_sorts - number of actual sorts taking place
                      (runs * total_num_jobs) over the entire experiment.
"""
import json
import multiprocessing
import platform
import subprocess
from pathlib import Path

from cpuinfo import get_cpu_info
from docopt import docopt

VERSION = "1.0.3"


def get_exec_version(exec_path: Path):
    """Call the process and parse the version information."""
    cmd = (str(exec_path), "--version")
    p = subprocess.Popen(cmd, stdout=subprocess.PIPE)
    stdout, _ = p.communicate()
    return stdout.decode().strip()


def get_supported_methods(exec_path: Path):
    """Call the process and parse the currently supported methods."""
    valid_methods = (
        subprocess.run(
            (str(exec_path), "--show-methods"),
            capture_output=True,
            check=True,
        )
        .stdout.decode()
        .split()
    )

    threshold_methods = (
        subprocess.run(
            (str(exec_path), "--show-methods=threshold"),
            capture_output=True,
            check=True,
        )
        .stdout.decode()
        .split()
    )
    valid_methods += threshold_methods

    valid_methods = tuple(set(valid_methods))
    threshold_methods = tuple(set(threshold_methods))
    return valid_methods, threshold_methods


def write_info(
    output_folder,
    command=None,
    concurrent="slurm",
    data_details_path=None,
    exec_path=None,
    runs=0,
    total_num_jobs=0,
    total_num_sorts=0,
    arcc_partition=None,
    base=True,
    callgrind=False,
    massif=False,
):
    """
    Write system information to disk.

    @param output_folder: Directory to write `job_details.json` to.
    @param command: Command used to create the job (src/jobs.py).
    @param concurrent: The number of threads used to run jobs concurrently.
    @param data_details_path: Path to input data metadata file.
    @param exec_path: Path to executable.
    @param runs: Number of times this particular dataset is rerun.
    @param total_num_jobs: Total number of jobs to be submitted.
    @param total_num_sorts: Total number of sorts to take place across all jobs.
    """
    if data_details_path is not None and data_details_path.is_file():
        with open(data_details_path, "r") as data_details_file:
            data_details = json.load(data_details_file)
    else:
        data_details = None

    vers = get_exec_version(exec_path)
    methods, threshold_methods = get_supported_methods(exec_path)

    info = {
        "Architecture": platform.architecture(),
        "Command": command,
        "Data Details": data_details,
        "Machine": platform.machine(),
        "Node": platform.node(),
        "Number of CPUs": multiprocessing.cpu_count(),
        "Number of concurrent jobs": concurrent,
        "Platform": platform.platform(),
        "Processor": platform.processor(),
        "CPU Info": get_cpu_info(),
        "Executable": {
            "Name": str(exec_path.name),
            "Version": vers,
            "Methods": {
                "All": methods,
                "Threshold": threshold_methods,
            },
        },
        "Release": platform.release(),
        "Runs": runs,
        "System": platform.system(),
        "Total number of jobs": total_num_jobs,
        "Total number of sorts": total_num_sorts,
        "Base": base,
        "Callgrind": callgrind,
        "Massif": massif,
        "ARCC Partition": arcc_partition,
        "Version": platform.version(),
    }

    with open(Path(output_folder, "job_details.json"), "w") as f:
        json.dump(info, f, indent=4)


if __name__ == "__main__":
    args = docopt(__doc__, version=VERSION)
    OUT_DIR = Path(args.get("DIR"))

    concurrent = args.get("--concurrent", 1)
    concurrent = int(concurrent)

    total_num_jobs = args.get("--total", 0)
    total_num_jobs = int(total_num_jobs)

    runs = args.get("--runs") or 1
    runs = int(runs)

    write_info(
        OUT_DIR,
        concurrent=concurrent,
        exec_path=args.get("--exec"),
        runs=runs,
        total_num_jobs=total_num_jobs,
        total_num_sorts=total_num_jobs * runs,
    )
